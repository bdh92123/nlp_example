{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pixiedust\n",
    "import sys, os\n",
    "from math import log, pow, e\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden Markov Model \n",
    "class HMM(object):\n",
    "    \"\"\"\n",
    "    start_prob: 시작확률 p(?|start)\n",
    "    trans_prob: 전이확률 p(t2|t1), etc...\n",
    "    emit_prob: 방출확률 p(o|t1), etc...\n",
    "    \"\"\"\n",
    "    def __init__(self, start_prob=None, trans_prob=None, emit_prob=None):\n",
    "        self.start_prob = start_prob\n",
    "        self.trans_prob = trans_prob\n",
    "        self.emit_prob = emit_prob\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    특정 상태집합으로 부터 전이 가능한 상태집합 구하는 함수\n",
    "    from_states: 특정 상태집합\n",
    "    return: 입력상태집합으로 부터 전이 가능한 상태집합\n",
    "    \"\"\"\n",
    "    def _get_to_states(self, from_states):\n",
    "        to_states = set([])\n",
    "        for state in from_states:\n",
    "            to_states = to_states.union(list(self.trans_prob[state].keys()))\n",
    "        return to_states\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Forward algorithm으로 Likelihood 계산\n",
    "    return: Probability table\n",
    "    \"\"\"\n",
    "    def forward(self, seq):\n",
    "        seq_len = len(seq)\n",
    "        a = [{}]\n",
    "        \n",
    "        # 시작확률로 부터 테이블 값 계산\n",
    "        for state in self.start_prob:\n",
    "            a[0][state] = self.start_prob[state] * self.emit_prob[state][seq[0]]\n",
    "        \n",
    "        # 나머지 시퀀스에 대해 확률 계산\n",
    "        to_states = self._get_to_states(list(self.start_prob.keys()))\n",
    "        for i in range(1, seq_len):\n",
    "            a.append({})\n",
    "            for to_state in to_states:\n",
    "                prob = 0\n",
    "                # 전이확률 * 방출확률 계산하여 테이블 저장\n",
    "                for from_state in list(a[i - 1].keys()):\n",
    "                    prob += a[i - 1][from_state] * self.trans_prob[from_state][to_state]\n",
    "                a[i][to_state] = prob * self.emit_prob[to_state][seq[i]]\n",
    "            # _get_to_states통해 매 시퀀스마다 다음 시퀀스에 대해 전이가능한 상태집합을 계산\n",
    "            if i != seq_len - 1:\n",
    "                to_states = self._get_to_states(to_states)\n",
    "        return a\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Viterbi algorithm으로 observation sequence에 대한 most likely state sequence 계산\n",
    "    seq: observation sequence array\n",
    "    return: most likely state sequence\n",
    "    \"\"\"\n",
    "    def viterbi(self, seq):\n",
    "        seq_len = len(seq)\n",
    "        v = {}\n",
    "        max_paths = []\n",
    "        # 확률 곱은 모두 log를 통해 정수 합 계산으로 변형\n",
    "        for to_state in self.start_prob:\n",
    "            # 시작확률 또는 방출확률이 없는 경우 lim{x->+0}(log(x))값을 -sys.maxsize로 계산\n",
    "            if self.start_prob[to_state] == 0 or self.emit_prob[to_state][seq[0]] == 0:\n",
    "                v[to_state] = -sys.maxsize\n",
    "            else:\n",
    "                v[to_state] = log(self.start_prob[to_state]) + log(self.emit_prob[to_state][seq[0]])\n",
    "        \n",
    "        # Viterbi value 계산\n",
    "        for i in range(1, seq_len):\n",
    "            cur_path = {}\n",
    "            temp_v = {}\n",
    "            to_states = self._get_to_states(list(v.keys()))\n",
    "            for to_state in to_states:\n",
    "                max_prob = -sys.maxsize\n",
    "                max_state = None\n",
    "                for from_state in list(v.keys()):\n",
    "                    prob = v[from_state] + log(self.trans_prob[from_state][to_state])\n",
    "                    if max_prob < prob:\n",
    "                        max_prob = prob\n",
    "                        max_state = from_state\n",
    "                # 방출확률이 없는 경우 최저확률로 계산\n",
    "                if self.emit_prob[to_state][seq[i]] == 0:\n",
    "                    temp_v[to_state] = max_prob - sys.maxsize\n",
    "                else:    \n",
    "                    temp_v[to_state] = max_prob + log(self.emit_prob[to_state][seq[i]])\n",
    "                cur_path[to_state] = max_state\n",
    "            v = temp_v\n",
    "            max_paths.append(cur_path)\n",
    "        \n",
    "        max_state = None\n",
    "        max_prob = -sys.maxsize\n",
    "        \n",
    "        # 마지막 상태부터 backtrace\n",
    "        for last_state in list(v.keys()):\n",
    "            if pow(e, v[last_state]) > max_prob:\n",
    "                max_prob = pow(e, v[last_state])\n",
    "                max_state = last_state\n",
    "                \n",
    "        # Viterbi path가 없는 경우\n",
    "        if max_state is None:\n",
    "            # print(\"viterbi path is none\")\n",
    "            return []\n",
    "        \n",
    "        viterbi_path = [max_state]\n",
    "        for i in range(seq_len - 1, 0, -1):\n",
    "            max_state = max_paths[i - 1][max_state]\n",
    "            viterbi_path.insert(0, max_state)\n",
    "            \n",
    "        return viterbi_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Construct Bigram table by corpus\n",
    "\"\"\" \n",
    "# 품사 Count\n",
    "pos_count = defaultdict(lambda:0, {})\n",
    "# 형태소/품사 Count\n",
    "morph_pos_count = defaultdict(lambda:0, {})\n",
    "# 품사접합 Count (t1|t2)\n",
    "bigram_pos_count = defaultdict(lambda:0, {})\n",
    "# 문장 개수\n",
    "sentence_count = 0\n",
    "\n",
    "# corpus로부터 Count table 계산\n",
    "o = open('train0.txt', encoding='euc-kr', newline='\\r\\n')\n",
    "last_pos = None\n",
    "for line in o.readlines():\n",
    "    line = line.strip()\n",
    "    if len(line) == 0:\n",
    "        last_pos = None\n",
    "        sentence_count += 1\n",
    "        continue\n",
    "    (word, morphs) = line.split('\\t')\n",
    "    for morph_pos in morphs.split('+'):\n",
    "        split_index = morph_pos.rfind('/')\n",
    "        (morph, pos) = (morph_pos[:split_index], morph_pos[split_index + 1:])\n",
    "        pos_count[pos] += 1\n",
    "        morph_pos_count[morph_pos] += 1\n",
    "        if last_pos is not None:\n",
    "            bigram_pos_count[f'{pos}|{last_pos}'] += 1\n",
    "        else:\n",
    "            bigram_pos_count[f'{pos}|$'] += 1\n",
    "        last_pos = pos\n",
    "o.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "테스트할 문장을 HMM의 Input에 맞게 Parsing\n",
    "\"\"\"\n",
    "\n",
    "# 문장별 형태소 분석 후보 로드\n",
    "o = open('result.txt', 'r+', encoding='euc-kr', newline='\\r\\n')\n",
    "\n",
    "# 문장 배열\n",
    "sentences = []\n",
    "# 한 어절에 대한 형태소분석 후보 배열\n",
    "word_morph_cases = []\n",
    "# 어절 배열\n",
    "sentence_word_morph_cases = []\n",
    "# Parsing 상태 값 (1: 새 어절, 2: 형태소후보)\n",
    "state = 1\n",
    "\n",
    "for line in o.readlines():\n",
    "    line = line.strip()\n",
    "    # 새 문장 시작\n",
    "    if len(line) == 0: \n",
    "        state = 1\n",
    "        if len(word_morph_cases) > 0:\n",
    "            sentence_word_morph_cases.append(word_morph_cases)\n",
    "            word_morph_cases = []\n",
    "        if len(sentence_word_morph_cases) > 0:\n",
    "            sentences.append(sentence_word_morph_cases)\n",
    "            sentence_word_morph_cases = []\n",
    "        continue\n",
    "\n",
    "    # 형태소 후보 행\n",
    "    if state == 2: \n",
    "        # 공백이 없으면 어절시작\n",
    "        if line.find(' ') == -1:\n",
    "            state = 1\n",
    "        else:\n",
    "            morphs = line.split(' ')[1].split('+')\n",
    "            word_morph_cases.append(tuple([tuple(morph.split('/')) for morph in morphs]))\n",
    "\n",
    "    # 새 어절 시작\n",
    "    if state == 1 and len(line) > 0:\n",
    "        state = 2\n",
    "        # 앞의 어절에 대한 형태소 후보 끝\n",
    "        if len(word_morph_cases) > 0:\n",
    "            sentence_word_morph_cases.append(word_morph_cases)\n",
    "            word_morph_cases = []\n",
    "\n",
    "if len(word_morph_cases) > 0:\n",
    "    sentence_word_morph_cases.append(word_morph_cases)\n",
    "if len(sentence_word_morph_cases) > 0:\n",
    "    sentences.append(sentence_word_morph_cases)\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('우리', 'NP'), ('집', 'NNG'), ('에', 'JKB')), (('왜', 'MAG'),), (('오', 'VV'), ('았', 'EP'), ('니', 'EF'), ('?', 'SF'))]\n",
      "[(('너', 'NP'), ('를', 'JKO')), (('사랑', 'NNG'), ('하', 'VV'), ('어', 'EF'), ('!', 'SF'))]\n",
      "[(('안녕', 'NNG'), ('하', 'XSV'), ('세', 'EC'), ('요', 'JX'))]\n"
     ]
    }
   ],
   "source": [
    "#%%pixie_debugger\n",
    "\"\"\"\n",
    "어절의 방출확률 계산\n",
    "\n",
    "word_morph_case: 어절의 형태소 정보. 다음과 같은 튜플 형태\n",
    "ex) 오/VX+았/EP+니/EF+?/SF == (('오','VX'),('았','EP'),('니','EF'),('?','SF'))\n",
    "일 때 방출확률은 p(오|VX)*p(EP|VX)*p(았|EP)*p(EF|EP)*p(니|EF)*p(SF|EF)*p(?|SF)\n",
    "\n",
    "return: 어절의 방출확률 (0~1)\n",
    "\"\"\"\n",
    "def get_emit_prob(word_morph_case):\n",
    "    # 확률은 log 합으로 계산하기에 초기 값은 0\n",
    "    prob = 0\n",
    "    for i in range(1, len(word_morph_case)):\n",
    "        from_pos = word_morph_case[i - 1][1]\n",
    "        to_pos = word_morph_case[i][1]\n",
    "        bigram_key = f'{to_pos}|{from_pos}'\n",
    "        if bigram_pos_count[bigram_key] == 0:\n",
    "            return 0\n",
    "        prob += log(bigram_pos_count[bigram_key] / pos_count[from_pos])\n",
    "    for i in range(0, len(word_morph_case)):\n",
    "        morph_pos_key = word_morph_case[i][0] + '/' + word_morph_case[i][1]\n",
    "        if morph_pos_count[morph_pos_key] == 0:\n",
    "            return 0\n",
    "        prob += log(morph_pos_count[morph_pos_key] / pos_count[word_morph_case[i][1]])\n",
    "    return pow(e, prob)\n",
    "\n",
    "o = open('output.txt', mode='w', encoding='euc-kr')\n",
    "# 문장별로 HMM 모델을 통해 가장 적합한 형태소 조합 결정\n",
    "# 단 어절자체가 상태 및 방출값이 되므로 별도의 방출값 집합은 갖지 않는 것으로 취급하여 계산한다.\n",
    "# 여기서는 모든 어절 상태에 관한 기본 방출가능 값은 0으로 (ex. emit_props[어절][0] = prob) 취급\n",
    "for sentence in sentences:\n",
    "    # HMM모델 Input 확률값들 계산\n",
    "    start_probs = {}\n",
    "    # map의 not exists key에 대한 default value를 empty map으로 하기위해 defaultdict 사용.\n",
    "    trans_probs =  defaultdict(lambda:{}, {})\n",
    "    emit_props = defaultdict(lambda:{}, {})\n",
    "    \n",
    "    # 첫번째 전이에 해당하는 시작확률 및 방출확률 계산\n",
    "    for word_morph_case in sentence[0]:\n",
    "        # P(pos|$)\n",
    "        prob = bigram_pos_count[word_morph_case[0][1] + '|$'] / sentence_count\n",
    "        start_probs[word_morph_case] = prob\n",
    "        emit_props[word_morph_case][0] = get_emit_prob(word_morph_case)\n",
    "        \n",
    "    # display(HTML(tabulate.tabulate([start_probs], tablefmt='html', headers='keys')))\n",
    "    # 두번째부터 나머지 어절에 관한 전이 및 방출확률 계산\n",
    "    seq = []\n",
    "    for i in range(1, len(sentence)):\n",
    "        sentence_prev_word_morph_cases = sentence[i - 1]\n",
    "        sentence_word_morph_cases = sentence[i]\n",
    "        for prev_word_morph_case in sentence_prev_word_morph_cases:\n",
    "            for word_morph_case in sentence_word_morph_cases:\n",
    "                from_morph = prev_word_morph_case[-1][1]\n",
    "                to_morph = word_morph_case[0][1]\n",
    "                trans_key = f'{to_morph}|{from_morph}'\n",
    "                prob = bigram_pos_count[trans_key] / pos_count[from_morph]\n",
    "                trans_probs[prev_word_morph_case][word_morph_case] = prob\n",
    "                emit_props[word_morph_case][0] = get_emit_prob(word_morph_case)\n",
    "                \n",
    "    # print(start_probs)\n",
    "    # print(trans_probs)\n",
    "    # print(emit_props)\n",
    "    \n",
    "    # HMM 모델에 확률 입력\n",
    "    model = HMM(start_probs, trans_probs, emit_props)\n",
    "    \n",
    "    # Viterbi algorithm로 most likely state sequence 출력\n",
    "    # 모든 어절의 방출가능 값을 0하나로 삼고 확률을 계산했으므로 Observation 시퀀스는 0으로 전달.\n",
    "    state_seq = model.viterbi([0 for i in range(0, len(sentence))])\n",
    "    print(state_seq)\n",
    "    \n",
    "    \n",
    "    tagged_sentence = ''\n",
    "    for state in state_seq:\n",
    "        word = []\n",
    "        for morph_pos in state:\n",
    "            word.append(f'{morph_pos[0]}/{morph_pos[1]}')\n",
    "        tagged_sentence += '+'.join(word) + ' '\n",
    "    o.write(tagged_sentence + os.linesep)\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  </th><th style=\"text-align: right;\">        hot</th><th style=\"text-align: right;\">       cold</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\"> 0</td><td style=\"text-align: right;\">0.32       </td><td style=\"text-align: right;\">0.02       </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 1</td><td style=\"text-align: right;\">0.08       </td><td style=\"text-align: right;\">0.014      </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 2</td><td style=\"text-align: right;\">0.01072    </td><td style=\"text-align: right;\">0.0202     </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 3</td><td style=\"text-align: right;\">0.0058048  </td><td style=\"text-align: right;\">0.0065632  </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 4</td><td style=\"text-align: right;\">0.00244326 </td><td style=\"text-align: right;\">0.00250394 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 5</td><td style=\"text-align: right;\">0.000493507</td><td style=\"text-align: right;\">0.00123983 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 6</td><td style=\"text-align: right;\">0.000316815</td><td style=\"text-align: right;\">9.41303e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 7</td><td style=\"text-align: right;\">9.10964e-05</td><td style=\"text-align: right;\">7.32817e-05</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 8</td><td style=\"text-align: right;\">3.35882e-05</td><td style=\"text-align: right;\">3.2163e-05 </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 9</td><td style=\"text-align: right;\">1.32073e-05</td><td style=\"text-align: right;\">3.27331e-06</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hot', 'hot', 'cold', 'cold', 'cold', 'cold', 'hot', 'hot', 'hot', 'hot']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple example. \n",
    "날씨에 따라 먹는 아이스크림 개수 예제\n",
    "\"\"\"\n",
    "\n",
    "start_prob = {\n",
    "    'hot' : 0.8,\n",
    "    'cold' : 0.2\n",
    "}\n",
    "\n",
    "trans_prob = {\n",
    "    'hot': { 'hot' : 0.6, 'cold' : 0.4 },\n",
    "    'cold': { 'hot' : 0.4, 'cold' : 0.6 }\n",
    "}\n",
    "\n",
    "emit_prob = {\n",
    "    'hot': { '1' : 0.2, '2' : 0.4, '3' : 0.4 },\n",
    "    'cold': { '1' : 0.5, '2' : 0.4, '3' : 0.1 }\n",
    "}\n",
    "\n",
    "model = HMM(start_prob, trans_prob, emit_prob)\n",
    "sequence = ['3', '3', '1', '2', '2', '1','3','2','2','3']\n",
    "\n",
    "# Likelihood 계산결과 observation 순서 별 table 값\n",
    "display(HTML(tabulate.tabulate(model.forward(sequence), tablefmt='html', headers='keys', showindex=True)))\n",
    "#print(model.forward(sequence))\n",
    "\n",
    "# 최적상태열 추정결과\n",
    "print(model.viterbi(sequence)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
